---
title: 数据预处理方法
date: 2019-4-24 17:29:12
categories:
    - 机器学习
tags: 
    - 数据处理
    - 机器学习
mathjax: true
---
### 引言

本文数据预处理与特征选择的代码均采用sklearn所提供的方法，并使用sklearn中的IRIS（鸢尾花）数据集来对特征处理功能进行说明，IRIS数据集由Fisher在1936年整理，包含4个特征：Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的3个分类：Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris Virginica（维吉尼亚鸢尾）。

### 归一化

我们学习Andrew Ng的机器学习课程时，用到的一个案列是买房时间与价格的。我们以此为例：我们在对数据进行分析的时候，往往会遇到单个数据的各个维度量纲不同的情况，比如对房子进行价格预测的线性回归问题中，房子的特征包括面积（平方米）、房间数（个）两个维度，采用梯度下降进行训练的过程如下图所示：

![梯度下降](https://s2.ax1x.com/2019/05/02/EtJEPx.png)

算法在寻找最优值的时候，由于图像“细长”，所以要来回找垂直线，两个特征的取值区间相差越大，图像就越“细长”，梯度下降就越慢，还可能永远无法收敛。因此需要使用归一化的方法将特征的取值区间缩放到某个特定的范围，例如[0, 1]等，下面介绍两种方法：

#### 区间缩放（Min-Max scaling）

区间缩放法将原始数据中特征的取值区间转换到[0 1]范围，归一化公式如下：

xnorm=x−xminxmax−xminxnorm=x−xminxmax−xmin

该方法实现对原始数据的等比例缩放，其中xx为原始数据，xnormxnorm为归一化后的数据，xmaxxmax和xminxmin分别为原始数据的最大值和最小值。使用preproccessing库的MinMaxScaler类对数据进行区间缩放的代码如下：
```python
from sklearn.preprocessing import MinMaxScaler

#区间缩放，返回值为缩放到[0, 1]区间的数据
MinMaxScaler().fit_transform(iris.data)
```

标准化（standardization）

该方法将原始数据归一化成均值为0、方差1的数据，归一化公式如下：

xnorm=x−μσxnorm=x−μσ

其中，μμ和σσ分别为原始数据的均值和方法。该种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。使用preproccessing库的StandardScaler类对数据进行标准化的代码如下：

```python
from sklearn.preprocessing import StandardScaler

#标准化，返回值为标准化后的数据
StandardScaler().fit_transform(iris.data)
```

该方法实现对原始数据的等比例缩放，其中xx为原始数据，xnormxnorm为归一化后的数据，xmaxxmax和xminxmin分别为原始数据的最大值和最小值。使用preproccessing库的MinMaxScaler类对数据进行区间缩放的代码如下：

```python
from sklearn.preprocessing import Normalizer

#归一化，返回值为归一化后的数据
Normalizer().fit_transform(iris.data)
```

### 特征二值化

特征二值化的方法是将特征的取值转化为0或1。例如，在房价预测问题中对于“是否为学区房”这一特征，取值为1表示该房是学区房，反之则为0。在sklearn中可以设置一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0。使用preproccessing库的Binarizer类对数据进行二值化的代码如下：

```python
from sklearn.preprocessing import Binarizer

#二值化，阈值设置为3，返回值为二值化后的数据
Binarizer(threshold=3).fit_transform(iris.data)
```

### one-hot编码

对于离散特征，例如，性别：｛男，女｝，可以采用one-hot编码的方式将特征表示为一个m维向量，其中m为特征的取值个数。在one-hot向量中只有一个维度的值为1，其余为0。以“性别”这个特征为例，我们可以用向量 “1，0”表示“男”，向量 “0，1”表示“女”。使用one-hot编码可将离散特征的取值扩展到了欧式空间，便于进行相似度计算。使用preproccessing库的OneHotEncoder类对数据进行one-hot编码的代码如下：

```python
from sklearn.preprocessing import OneHotEncoder

#对IRIS数据集的目标值进行one-hot编码
OneHotEncoder().fit_transform(iris.target.reshape((-1,1)))
```

### 缺失值计算

在实际应用中，我们得到的数据往往不完整，可以用以下方法进行处理：

最简单直接的方法是删除含有缺失值的数据删，这种做法的缺点是可能会导致信息丢失

通过已有数据计算相应特征的平均数、中位数、众数等来补全缺失值

建立一个模型来“预测”缺失的数据。（KNN, Matrix completion等方法）

引入虚拟变量(dummy variable)来表征是否有缺失，是否有补全

用preproccessing库的Imputer类对数据进行缺失值计算的代码如下：

```python
from numpy import vstack, array, nan
from sklearn.preprocessing import Imputer

#缺失值计算，返回值为计算缺失值后的数据
#参数missing_value为缺失值的表示形式，默认为NaN
#对数据集新增一个样本，4个特征均赋值为NaN，表示数据缺失
#参数strategy为缺失值填充方式，默认为mean（均值）
Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data)))
```

### 数据变换

常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的。4个特征，度为2的多项式转换公式如下：

使用preproccessing库的PolynomialFeatures类对数据进行多项式转换的代码如下：

```python
from sklearn.preprocessing import PolynomialFeatures

#多项式转换
#参数degree为度，默认值为2
PolynomialFeatures().fit_transform(iris.data)
```

基于单变元函数的数据变换可以使用一个统一的方式完成，使用preproccessing库的FunctionTransformer对数据进行对数函数转换的代码如下：

```python
from numpy import log1p
from sklearn.preprocessing import FunctionTransformer

#自定义转换函数为对数函数的数据变换
#第一个参数是单变元函数
FunctionTransformer(log1p).fit_transform(iris.data)
```

### 样本不均衡

样本不均衡指的是数据集中的正样本数量与负样本数量的比例失衡。例如，实际应用中，负样本的数量通常远远大于正样本。样本不均衡的危害：造成分类器在多数类精度较高，少数类的分类精度很低，甚至造成分类器失效。解决方案分为以下两种：

*   欠采样：通过减少多数类样本来提高少数类的分类性能

    随机地去掉一些多数类样本来减小多数类的规模，该方法的缺点是会丢失多数类的一些重要信息，不能够充分利用已有的信息

    通过一定规则有选择的去掉对分类作用不大的多数样本（保留与正样本较为接近的负样本）
*   过抽样：通过改变训练数据的分布来消除或减小数据的不平衡

    对少数类样本进行复制，该方法的缺点是可能导致过拟合，因为没有给少数类增加任何新的信息
*   算法层面

    改进损失函数的权重，加大少数样本的权值

    采用集成学习（bagging, boosting）